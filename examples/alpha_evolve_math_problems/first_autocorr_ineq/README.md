# B.1. First autocorrelation inequality

For any function $f:\mathbb{R} \rightarrow \mathbb{R}$, define the *autoconvolution* of $f$, written $f*f$, as
$$f*f (t) := \int_\mathbb{R} f(t-x) f(x)\ dx.$$

Let $C_1$ denote the largest constant for which one has
$$\max_{-1/2 \leq t \leq 1/2} f*f(t) \geq C_1 \left(\int_{-1/4}^{1/4} f(x)\ dx\right)^2$$
for all non-negative $f: \mathbb{R} \rightarrow \mathbb{R}$. This problem arises in additive combinatorics, relating to the size of Sidon sets. It is currently known that
$$1.28 \leq C_1 \leq 1.5098$$
with the lower bound proven by [Cloninger and Steinerberger (2017)](https://www.ams.org/journals/proc/2017-145-08/S0002-9939-2017-13690-9/S0002-9939-2017-13690-9.pdf) and the upper bound achieved by [Matolcsi and Vinuesa (2010)](https://www.sciencedirect.com/science/article/pii/S0022247X10006001) via a step function construction. AlphaEvolve [1] found a step function with 600 equally-spaced intervals on $[-1/4,1/4]$ that gives a better upper bound of $C_1 \leq 1.5053$.


## Implementation in ShinkaEvolve

This folder contains an implementation of the problem detailed in **Annex B.1** of the AlphaEvolve paper [1]. 

Because the original AlphaEvolve codebase is not publicly available, this implementation was adapted from open-source implementations to work within ShinkaEvolve.
All credits go to the authors of the original code. The files in this repository were adapted for ShinkaEvolve from the following sources:

* **Verification Code:** Adapted from the [Test-time-discover repository [2]](https://github.com/test-time-training/discover/blob/main/tasks/alphaevolve_ac/verifier_ae.py).
* **Initial Programs:** Two variations are included, alongside their respective configuration files.
    * *Variation 1:* Sourced from [Test-time-discover [2] repository](https://github.com/test-time-training/discover/blob/main/tasks/alphaevolve_ac/prompt.py).
    * *Variation 2:* Sourced from OpenEvolve (originally implemented by Codeevolve). See the [source file](https://github.com/algorithmicsuperintelligence/openevolve/blob/main/examples/alphaevolve_math_problems/first_autocorr_ineq/initial_program.py) and [Pull Request #302](https://github.com/algorithmicsuperintelligence/openevolve/pull/302).


## Results with ShinkaEvolve

Using **GPT-oss-120b** as the underlying LLM, we evaluated the best $C_1$ score generated by each of the initial programs:


| Initial Program | Score | Best $C_1$ | LLM | DB Budget | Evol. Budget | Generations | Variant File
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :---
| **OpenEvolve** | 0.997 |`1.5103567661361352` | GPT-oss-120b | Medium | Medium | 500 | configs/variant/alpha_evolve_math_problems/first_autocorr_ineq/open_evolve.yaml
| **Test-time-discover** | 0.985 |  `1.5279153570786084` | GPT-oss-120b | Medium | Medium | 500 | configs/variant/alpha_evolve_math_problems/first_autocorr_ineq/test_time_discover.yaml

> **Note:** AlphaEvolve [1] got 1.5053. Test-time discover [2] got 1.50287. 

Feel free to add your own results!


## How to use?

To reproduce these results or run your own evolution experiments, follow these steps:

1.  **Install Dependencies:** Ensure you have the required environment set up by installing the dependencies listed in:
    `examples/alpha_evolve_math_problems/pyproject.toml`
2.  **Configure Variants:** Adjust the evolution parameters or model settings by editing the variant configuration files located here:
    `configs/variant/alpha_evolve_math_problems/first_autocorr_ineq`
3.  **(Optional) Visualize Results:** After running the evolution, you can analyze the generated step functions and $C_1$ convergence using the provided notebook:
    `examples/alpha_evolve_math_problems/first_autocorr_ineq/visualization.ipynb`


----
## References

[1] **AlphaEvolve:** Novikov, A., Vũ, N., Eisenberger, M., Dupont, E., Huang, P.-S., Wagner, A. Z., ... & Balog, M. (2025). *AlphaEvolve: A coding agent for scientific and algorithmic discovery*. arXiv preprint [arXiv:2506.13131](https://arxiv.org/abs/2506.13131).

[2] **Test-time Discover:** Yuksekgonul, M., Koceja, D., Li, X., Bianchi, F., McCaleb, J., Wang, X., ... & Sun, Y. (2026). *Learning to Discover at Test Time*. arXiv preprint [arXiv:2601.16175](https://arxiv.org/abs/2601.16175).

[3] **CodeEvolve:** Assumpção, H., Ferreira, D., Campos, L., & Murai, F. (2025). *CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization*. arXiv preprint [arXiv:2510.14150](https://arxiv.org/abs/2510.14150).

[4] **OpenEvolve:** Sharma, A. (2025). *OpenEvolve: Open-source implementation of AlphaEvolve*. [GitHub Repository](https://github.com/algorithmicsuperintelligence/openevolve).

**External Links:**
* [Google DeepMind Colab](https://colab.research.google.com/github/google-deepmind/alphaevolve_results/blob/master/mathematical_results.ipynb#scrollTo=IBOyCNqLeJ2S) — Check the original result from AlphaEvolve and view a simplified version of the verification code provided by Google.